{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "subject_id = 1\n",
    "npy_dir =root + f'\\data\\preprocess\\S{subject_id:>02d}\\\\'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的数据集 尺寸为 980 * 64 * 256\n",
    "\n",
    "但是为了和图片尺寸一致 我们添加 为 980 * 1 * 64 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(npy_dir + 'x.npy')\n",
    "y = np.load(npy_dir + 'y.npy')\n",
    "x= torch.from_numpy(x).float() #转化成张量 浮点型\n",
    "y=  torch.from_numpy(y)\n",
    "x= torch.unsqueeze(x,1) #squeeze是压缩的意思，unsqueeze是添加维度，解压缩,后面的1是指维度\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rate = 0.75\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(x)\n",
    "train_num = int(total_num * train_rate)\n",
    "train_dataset = torch.utils.data.TensorDataset(x[:train_num],y[:train_num])\n",
    "test_dataset = torch.utils.data.TensorDataset(x[train_num:],y[train_num:])\n",
    "train_data_loader  = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = True)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                shuffle = False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型\n",
    "\n",
    "这里先把模型放在这里，训练过程写好，等下再解析模型\n",
    "\n",
    "1.模型输入16 * 1 * 64 * 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InputBlockTime(torch.nn.Module):\n",
    "    def __init__(self, time_channels, time_size, spatial_channels, spatial_size, pool_param=(1, 2), dropout=0.5):\n",
    "        super(InputBlockTime, self).__init__()\n",
    "\n",
    "        self.block = torch.nn.Sequential(\n",
    "            # time filter\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=time_channels,\n",
    "                            kernel_size=time_size, padding=(0, time_size[1] // 2), bias=False),\n",
    "\n",
    "\n",
    "            # spatial filter\n",
    "            torch.nn.Conv2d(in_channels=time_channels, groups=time_channels,\n",
    "                            out_channels=spatial_channels, kernel_size=spatial_size),\n",
    "\n",
    "            torch.nn.BatchNorm2d(spatial_channels),\n",
    "            torch.nn.ELU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=pool_param,\n",
    "                               stride=pool_param),\n",
    "            torch.nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeatureBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_param=(1, 15), pool_param=(1, 2), dropout=0.5, padding=(-1, -1, -1, -1)):\n",
    "        super(FeatureBlock, self).__init__()\n",
    "        if (padding[0] == -1):\n",
    "            padding = (conv_param[1] // 2, conv_param[1] // 2, 0, 0)\n",
    "\n",
    "        self.padding = torch.nn.ZeroPad2d(padding=padding)\n",
    "\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=conv_param,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.norm = torch.nn.BatchNorm2d(\n",
    "            num_features=out_channels\n",
    "        )\n",
    "\n",
    "        self.elu = torch.nn.ELU()\n",
    "\n",
    "        self.pool = torch.nn.MaxPool2d(\n",
    "            kernel_size=pool_param,\n",
    "            stride=pool_param\n",
    "        )\n",
    "\n",
    "        self.drop_out = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.padding(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.elu(x)\n",
    "        x = self.pool(x)\n",
    "        return self.drop_out(x)\n",
    "\n",
    "\n",
    "class DeepConvNet(torch.nn.Module):\n",
    "    def __init__(self, sample, class_num, time_channels, time_size,\n",
    "                 spatial_channels, spatial_size,\n",
    "                 feature_pool_size, feature_channels_list, dropout):\n",
    "        super(DeepConvNet, self).__init__()\n",
    "\n",
    "        self.input_block = InputBlockTime(time_channels=time_channels, time_size=time_size,\n",
    "                                          spatial_channels=spatial_channels, spatial_size=spatial_size,\n",
    "                                          pool_param=feature_pool_size, dropout=dropout)\n",
    "\n",
    "        self.feature_block_list = torch.nn.Sequential()\n",
    "        pre_channels = spatial_channels\n",
    "        for channel in feature_channels_list:\n",
    "            self.feature_block_list.add_module(\n",
    "                f\"feature {channel}\",\n",
    "                FeatureBlock(in_channels=pre_channels, out_channels=channel,\n",
    "                             pool_param=feature_pool_size, dropout=dropout)\n",
    "            )\n",
    "            pre_channels = channel\n",
    "\n",
    "        # 造一个数据来得到全连接层之前数据的 shape\n",
    "        # 这样就不用手动计算数据的 shape 了，是一个实用技巧\n",
    "        tmp_data = torch.Tensor(np.ones((1, 1, 64, sample), dtype=float))\n",
    "        tmp_data = self.input_block(tmp_data)\n",
    "        tmp_data = self.feature_block_list(tmp_data)\n",
    "        tmp_data = tmp_data.view(tmp_data.size(0), -1)\n",
    "\n",
    "        self.classifer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(tmp_data.shape[1],\n",
    "                            class_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out2 = self.input_block(x)\n",
    "        x = self.feature_block_list(out2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifer(x)\n",
    "        return torch.nn.functional.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepConvNet(\n",
    "        sample=256, class_num=2,\n",
    "        time_channels=25, time_size=(1, 9),\n",
    "        spatial_channels=50, spatial_size=(64, 1),\n",
    "        feature_pool_size=(1, 3), feature_channels_list=[100, 200], dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1 / 10\tTrain_loss:30.6454\n",
      "epochs: 2 / 10\tTrain_loss:27.1768\n",
      "epochs: 3 / 10\tTrain_loss:23.5734\n",
      "epochs: 4 / 10\tTrain_loss:21.3702\n",
      "epochs: 5 / 10\tTrain_loss:21.9127\n",
      "epochs: 6 / 10\tTrain_loss:20.8666\n",
      "epochs: 7 / 10\tTrain_loss:19.8323\n",
      "epochs: 8 / 10\tTrain_loss:19.0817\n",
      "epochs: 9 / 10\tTrain_loss:18.6752\n",
      "epochs: 10 / 10\tTrain_loss:17.5857\n",
      "\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #得到服务器\n",
    "model  = model.to(device) #将模型放在服务器上\n",
    "loss_func = torch.nn.CrossEntropyLoss() #设置损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters() ) #设置梯度下降的优化器\n",
    "\n",
    "for epoch in range(epochs): #不断循环利用这个dataloader来训练\n",
    "    running_loss = 0.0\n",
    "    batch_size = None\n",
    "    size_loss = 0 #这几个参数为什么这么设还不知道\n",
    "\n",
    "    for index,data in enumerate(train_data_loader): #这是对于一个batch_size（16个样本拼在一起）的训练\n",
    "        x,y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        model_out = model(x)\n",
    "\n",
    "        loss = loss_func(model_out,y.long()) #利用loss函数求解损失值 （将y转换为long形式）\n",
    "        optimizer.zero_grad() #梯度清零,之所以要清理，是因为每次反传都会产生新的梯度\n",
    "        loss.backward() #反传\n",
    "        optimizer.step() #梯度下降\n",
    "        running_loss += float(loss.item()) \n",
    "\n",
    "    print(f'epochs: {epoch+1} / {epochs}\\tTrain_loss:{running_loss:.4f}',end = '\\n') #这里的f应该是format的简写，即为格式化输出{}的内容\n",
    "print('\\nFinished training')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test acc:0.9020408163265307\n"
     ]
    }
   ],
   "source": [
    "correct_num = 0\n",
    "total_num = 0\n",
    "for index,data in enumerate(test_data_loader):\n",
    "    x,y = data\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    model_out = model(x)\n",
    "    _, pred = torch.max(model_out, 1)\n",
    "    correct_num += np.sum(pred.cpu().numpy()==y.cpu().numpy()) \n",
    "    #这一步是转换到cpu，然后转换为numpy\n",
    "    total_num +=len(y)\n",
    "print('\\nTest acc:'+str(correct_num/total_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "out = model(x)   # 将 x 输入网络\n",
    "g = make_dot(out)  # 实例化 make_dot\n",
    "g.view()  # 直接在当前路径下保存 pdf 并打开\n",
    "# g.render(filename='netStructure/myNetModel', view=False, format='pdf')  # 保存 pdf 到指定路径不打开\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44ecba1be7491a5bc153ef91d6a574d9526dcd4a0fdd78aab2e1c84520780719"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
